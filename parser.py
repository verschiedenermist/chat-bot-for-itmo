# -*- coding: utf-8 -*-
"""parser

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iVCn73A-4_1-tQAHcl4QtSFN-lBwc53B
"""

import requests
from bs4 import BeautifulSoup
import json
import pandas as pd
from pathlib import Path
import os

BASE_DIR = Path(os.path.dirname(os.path.abspath(__file__))).parent
DATA_DIR = BASE_DIR / 'data'
DATA_DIR.mkdir(exist_ok=True)

def parse_program(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')

        program_data = {
            'title': soup.find('h1').get_text(strip=True),
            'description': soup.find('div', class_='program-description').get_text(strip=True),
            'subjects': []
        }

        for subject in soup.select('.subject-list .subject-item'):
            program_data['subjects'].append({
                'name': subject.find('div', class_='subject-name').get_text(strip=True),
                'credits': subject.find('div', class_='subject-credits').get_text(strip=True),
                'type': 'Обязательный' if 'required' in subject.get('class', []) else 'Выборный'
            })

        return program_data
    except Exception as e:
        print(f"Ошибка парсинга {url}: {e}")
        return None

def save_program_data(program, filename):
    with open(DATA_DIR / filename, 'w', encoding='utf-8') as f:
        json.dump(program, f, ensure_ascii=False, indent=2)

def load_program_data(filename):
    try:
        with open(DATA_DIR / filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return None

def update_all_programs():
    programs = {
        'ai': 'https://abit.itmo.ru/program/master/ai',
        'ai_product': 'https://abit.itmo.ru/program/master/ai_product'
    }

    for name, url in programs.items():
        data = parse_program(url)
        if data:
            save_program_data(data, f'{name}.json')

if __name__ == '__main__':
    update_all_programs()